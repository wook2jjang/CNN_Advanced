{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67f3afc",
   "metadata": {},
   "source": [
    "# torch에서 몇몇 모델들을 기본적으로 제공해주긴 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import alexnet\n",
    "from torchvision.models import vgg16\n",
    "from torchvision.models import googlenet\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models import densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6959126",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a49a2a",
   "metadata": {},
   "source": [
    "## 그래도 한번씩 모델을 직접 짜보도록 하죠."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae0db27",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c76dbff",
   "metadata": {},
   "source": [
    "<img src=\"img/AlexNet.png\" width=\"600px\" height=\"400px\"></img><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c60564",
   "metadata": {},
   "source": [
    "<img src=\"img/alexnet(2).png\" width=\"600px\" height=\"800px\"></img><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a903b4",
   "metadata": {},
   "source": [
    "<span style = 'font-size:1.4em;line-height:1.5em'>Input Size가 224\\*224\\*3이 아닌 227\\*227\\*3으로 변경되었습니다. 관련 자료는 아래 link를 참조하세요</span>\n",
    "\n",
    "https://datascience.stackexchange.com/questions/29245/what-is-the-input-size-of-alex-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389dce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000, dropout=0.5):\n",
    "        super(MyAlexNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3, 96, kernel_size=11, stride=4),\n",
    "                                   nn.ReLU(inplace=True), \n",
    "                                   nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(96,256,kernel_size=5, padding=2), \n",
    "                                   nn.ReLU(inplace=True), \n",
    "                                   nn.MaxPool2d(kernel_size=3,stride=2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(256, 384, kernel_size=3, padding=1), \n",
    "                                   nn.ReLU(inplace=True))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(384, 384, kernel_size=3, padding=1), \n",
    "                                   nn.ReLU(inplace=True))\n",
    "        self.conv5 = nn.Sequential(nn.Conv2d(384, 256, kernel_size=3, padding=1), \n",
    "                                   nn.ReLU(inplace=True), \n",
    "                                   nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        self.fc = nn.Sequential(nn.Dropout(p=dropout),\n",
    "                                nn.Linear(6*6*256, 4096), \n",
    "                                nn.ReLU(inplace=True), \n",
    "                                nn.Dropout(p=dropout), \n",
    "                                nn.Linear(4096,4096), \n",
    "                                nn.ReLU(inplace=True), \n",
    "                                nn.Linear(4096, num_classes))\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, submodule):\n",
    "        if isinstance(submodule, nn.Conv2d):\n",
    "            nn.init.xavier_normal_(submodule.weight)\n",
    "            if submodule.bias is not None:\n",
    "                submodule.bias.data.fill_(0)\n",
    "        if isinstance(submodule, nn.Linear): # submodule이 nn.Linear에서 생성된 객체(혹은 인스턴스이면)\n",
    "            nn.init.kaiming_normal_(submodule.weight) #해당 submodule의 weight는 He Initialization으로 초기화\n",
    "            if submodule.bias is not None:\n",
    "                submodule.bias.data.fill_(0) # 해당 submodule의 bias는 0으로 초기화\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "        out = F.softmax(x, dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyAlexNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0621b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 227, 227), device=device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90482be7",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1175e93",
   "metadata": {},
   "source": [
    "<img src=\"img/vgg16.png\" width=\"600px\" height=\"800px\"></img><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf3be59",
   "metadata": {},
   "source": [
    "<img src=\"img/VGG16(2).png\" width=\"600px\" height=\"400px\"></img><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layer(config):\n",
    "    layers = []\n",
    "    in_planes = 3\n",
    "    for value in config:\n",
    "        if value == \"M\":\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        else:\n",
    "            layers.append(nn.Conv2d(in_planes, value, kernel_size=3, padding=1))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_planes = value\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cea864",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_configs = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfb4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = make_layer(vgg16_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecdd9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a01260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVGG16(nn.Module):\n",
    "    def __init__(self, num_classes=1000, dropout=0.5, initialize_weight = False):\n",
    "        super(MyVGG16, self).__init__()\n",
    "        self.convs = make_layer(vgg16_configs)\n",
    "        self.fc = nn.Sequential(nn.Linear(512 * 7 * 7, 4096),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(4096, 4096),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(4096, num_classes))\n",
    "        if initialize_weight:\n",
    "            self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "        out = F.softmax(x, dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce10cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyVGG16().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1344881",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(3, 227, 227), device=device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1063bb70",
   "metadata": {},
   "source": [
    "## GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61014941",
   "metadata": {},
   "source": [
    "<img src=\"img/GoogleNet.png\"></img><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcba57f",
   "metadata": {},
   "source": [
    "<img src=\"img/GoogleNet(2).png\"></img><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf5a40",
   "metadata": {},
   "source": [
    "(참고: https://devlee247.com/papers/2022-06-20-googlenet/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c475ea",
   "metadata": {},
   "source": [
    "### Step1. Inception Module 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BaseConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.ReLU(self.conv(x))\n",
    "\n",
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3_red, ch3x3, ch5x5_red, ch5x5, pool):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        \n",
    "        self.conv1x1 = nn.Conv2d(in_channels, ch1x1, kernel_size=1)\n",
    "        \n",
    "        self.conv3x3 = nn.Sequential(BaseConv2d(in_channels, ch3x3_red, kernel_size=1),\n",
    "                                     BaseConv2d(ch3x3_red, ch3x3, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv5x5 = nn.Sequential(BaseConv2d(in_channels, ch5x5_red, kernel_size=1),\n",
    "                                     BaseConv2d(ch5x5_red, ch5x5, kernel_size=5, padding=2))\n",
    "        \n",
    "        self.pool = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                                  BaseConv2d(in_channels, pool, kernel_size=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1x1(x)\n",
    "        x2 = self.conv3x3(x)\n",
    "        x3 = self.conv5x5(x)\n",
    "        x4 = self.pool(x)\n",
    "        \n",
    "        # x1,x2,x3,x4는 각각 (batch_size, n_channel, height, width)로 된 4차원 tensor\n",
    "        # channel concat --> 1차원 방향으로 concatenate\n",
    "        return torch.cat([x1, x2, x3, x4], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e91a332",
   "metadata": {},
   "source": [
    "### step2. Auxiliary Module 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb139c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxModule(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(AuxModule, self).__init__()\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((4,4))\n",
    "        self.conv1 = BaseConv2d(in_channels, 128, kernel_size=1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(4*4*128, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.7),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avgpool(x)\n",
    "        x = self.conv1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb64bc9f",
   "metadata": {},
   "source": [
    "### Step3. GoogLeNet 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76436afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGoogleNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(MyGoogleNet, self).__init__()\n",
    "        self.is_training=True\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3,64,kernel_size=7, stride=2, padding=3), \n",
    "                                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                                   nn.LocalResponseNorm(2))\n",
    "        \n",
    "        self.conv2 = nn.Sequential(BaseConv2d(64, 64, kernel_size=1),\n",
    "                                   BaseConv2d(64, 192, kernel_size=3, padding=1),\n",
    "                                   nn.LocalResponseNorm(2),\n",
    "                                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "        \n",
    "        self.inception_3a = InceptionModule(in_channels=192, \n",
    "                                            ch1x1=64, \n",
    "                                            ch3x3_red=96, \n",
    "                                            ch3x3=128, \n",
    "                                            ch5x5_red=16, \n",
    "                                            ch5x5=32, \n",
    "                                            pool=32)\n",
    "        self.inception_3b = InceptionModule(in_channels=256, \n",
    "                                            ch1x1=128, \n",
    "                                            ch3x3_red=128, \n",
    "                                            ch3x3=192, \n",
    "                                            ch5x5_red=32, \n",
    "                                            ch5x5=96, \n",
    "                                            pool=64)\n",
    "        self.maxpool_3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception_4a = InceptionModule(in_channels=480, \n",
    "                                            ch1x1=192, \n",
    "                                            ch3x3_red=96, \n",
    "                                            ch3x3=208, \n",
    "                                            ch5x5_red=16, \n",
    "                                            ch5x5=48, \n",
    "                                            pool=64)\n",
    "        self.aux1 = AuxModule(512, num_classes)\n",
    "\n",
    "        self.inception_4b = InceptionModule(in_channels=512, \n",
    "                                            ch1x1=160, \n",
    "                                            ch3x3_red=112, \n",
    "                                            ch3x3=224, \n",
    "                                            ch5x5_red=24, \n",
    "                                            ch5x5=64, \n",
    "                                            pool=64)\n",
    "        self.inception_4c = InceptionModule(in_channels=512, \n",
    "                                            ch1x1=128, \n",
    "                                            ch3x3_red=128, \n",
    "                                            ch3x3=256,\n",
    "                                            ch5x5_red=24,\n",
    "                                            ch5x5=64,\n",
    "                                            pool=64)\n",
    "        self.inception_4d = InceptionModule(in_channels=512,\n",
    "                                            ch1x1=112,\n",
    "                                            ch3x3_red=144,\n",
    "                                            ch3x3=288,\n",
    "                                            ch5x5_red=32,\n",
    "                                            ch5x5=64,\n",
    "                                            pool=64)\n",
    "        self.aux2 = AuxModule(528, num_classes)\n",
    "\n",
    "        self.inception_4e = InceptionModule(in_channels=528,\n",
    "                                            ch1x1=256,\n",
    "                                            ch3x3_red=160,\n",
    "                                            ch3x3=320,\n",
    "                                            ch5x5_red=32,\n",
    "                                            ch5x5=128,\n",
    "                                            pool=128)\n",
    "        self.maxpool_4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception_5a = InceptionModule(in_channels=832, \n",
    "                                            ch1x1=256, \n",
    "                                            ch3x3_red=160,\n",
    "                                            ch3x3=320,\n",
    "                                            ch5x5_red=32,\n",
    "                                            ch5x5=128,\n",
    "                                            pool=128)\n",
    "        self.inception_5b = InceptionModule(in_channels=832,\n",
    "                                            ch1x1=384,\n",
    "                                            ch3x3_red=192,\n",
    "                                            ch3x3=384,\n",
    "                                            ch5x5_red=48,\n",
    "                                            ch5x5=128,\n",
    "                                            pool=128)\n",
    "\n",
    "        # AdaptiveAvgPool explanation\n",
    "        # https://stackoverflow.com/questions/58692476/what-is-adaptive-average-pooling-and-how-does-it-work\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout2d(p=0.4)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = self.inception_3a(x)\n",
    "        x = self.inception_3b(x)\n",
    "        x = self.maxpool_3(x)\n",
    "\n",
    "        x = self.inception_4a(x)\n",
    "        if self.is_training:\n",
    "            out1 = self.aux1(x)\n",
    "\n",
    "        x = self.inception_4b(x)\n",
    "        x = self.inception_4c(x)\n",
    "        x = self.inception_4d(x)\n",
    "        if self.is_training:\n",
    "            out2 = self.aux2(x)\n",
    "\n",
    "        x = self.inception_4e(x)\n",
    "        x = self.maxpool_4(x)\n",
    "\n",
    "        x = self.inception_5a(x)\n",
    "        x = self.inception_5b(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc(x)                \n",
    "        if self.is_training:\n",
    "            return [x, out1, out2]\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9297e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyGoogleNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59989f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(3, 227, 227), device=device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadb3cd2",
   "metadata": {},
   "source": [
    "## ResNet (18-layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c18f53",
   "metadata": {},
   "source": [
    "<img src=\"img/resnet.png\"></img><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048cac84",
   "metadata": {},
   "source": [
    "<img src=\"img/resnet(2).png\"></img><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcd0a69",
   "metadata": {},
   "source": [
    "### 18-layer resnet구현해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_ch, out_ch, stride=1, groups=1, dilation=1):\n",
    "    r\"\"\"\n",
    "    3x3 convolution with padding\n",
    "    - in_planes: in_channels\n",
    "    - out_channels: out_channels\n",
    "    - bias=False: BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7292e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d15a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet18(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(MyResNet18, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.zero_init_residual = zero_init_residual\n",
    "        \n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        \n",
    "        # each element in the tuple indicates if we should replace\n",
    "        # the 2x2 stride with a dilated convolution instead\n",
    "        if replace_stride_with_dilation is None:    \n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        \n",
    "        \n",
    "        # 구조 정의\n",
    "        self.conv1   = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1     = norm_layer(self.inplanes)\n",
    "        self.relu    = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.block2 = self._make_layer(block, 64, layers[0])\n",
    "        self.block3 = self._make_layer(block, 128, layers[1], stride=2, \n",
    "                                       dilate = replace_stride_with_dilation[0])\n",
    "        self.block4 = self._make_layer(block, 256, layers[2], stride=2, \n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.block5 = self._make_layer(block, 512, layers[3], stride=2, \n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*block.expansion, num_classes)\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        if self.zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "                \n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "#     def _forward_impl(self, x):\n",
    "#         # See note [TorchScript super()]\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.maxpool(x)\n",
    "\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.layer3(x)\n",
    "#         x = self.layer4(x)\n",
    "\n",
    "#         x = self.avgpool(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc(x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        result = self.fc(x)\n",
    "        return result\n",
    "        \n",
    "#         return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ef4be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyResNet18(block=BasicBlock, layers=[2,2,2,2]).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8198f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(3, 224, 224), device=device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a35afb1",
   "metadata": {},
   "source": [
    "## DenseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e013891e",
   "metadata": {},
   "source": [
    "<img src=\"img/DenseNet.png\"></img><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982e17a4",
   "metadata": {},
   "source": [
    "<img src=\"img/DenseNet(2).png\"></img><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dec2d1",
   "metadata": {},
   "source": [
    "### (1) BottleNeck 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560472b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        inner_channels = 4 * growth_rate\n",
    "\n",
    "        self.residual = nn.Sequential(nn.BatchNorm2d(in_channels),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Conv2d(in_channels, inner_channels, 1, stride=1, padding=0, bias=False),\n",
    "                                      nn.BatchNorm2d(inner_channels),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Conv2d(inner_channels, growth_rate, 3, stride=1, padding=1, bias=False))\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.shortcut(x), self.residual(x)], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0300e75a",
   "metadata": {},
   "source": [
    "### (2) Transition layer구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Transition, self).__init__()\n",
    "        self.down_sample = nn.Sequential(nn.BatchNorm2d(in_channels),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False),\n",
    "                                         nn.AvgPool2d(2, stride=2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.down_sample(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd58201e",
   "metadata": {},
   "source": [
    "### (3) DenseNet구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5ff71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseNet121(nn.Module):\n",
    "    def __init__(self, nblocks, growth_rate=12, reduction=0.5, num_classes=10, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.growth_rate = growth_rate\n",
    "        inner_channels = 2 * growth_rate # output channels of conv1 before entering Dense Block\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3, inner_channels, 7, stride=2, padding=3),\n",
    "                                   nn.MaxPool2d(3, 2, padding=1))\n",
    "\n",
    "        self.features = nn.Sequential()\n",
    "        \n",
    "        \n",
    "        ## Dense block, transition layer 1~3까지 생성\n",
    "        for i in range(len(nblocks)-1):\n",
    "            self.features.add_module('dense_block_{}'.format(i), self._make_dense_block(nblocks[i], inner_channels))\n",
    "            inner_channels += growth_rate * nblocks[i]\n",
    "            out_channels = int(reduction * inner_channels) #downsampling out_channel\n",
    "            self.features.add_module('transition_layer_{}'.format(i), Transition(inner_channels, out_channels))\n",
    "            inner_channels = out_channels \n",
    "        \n",
    "        ## Dense block 4생성\n",
    "        self.features.add_module('dense_block_{}'.format(len(nblocks)-1), self._make_dense_block(nblocks[len(nblocks)-1], inner_channels))\n",
    "        inner_channels += growth_rate * nblocks[len(nblocks)-1]\n",
    "        self.features.add_module('bn', nn.BatchNorm2d(inner_channels))\n",
    "        self.features.add_module('relu', nn.ReLU())\n",
    "        \n",
    "        ## Global Avg를 AdaptiveAvgPool2d를 사용하여 수행\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.linear = nn.Linear(inner_channels, num_classes)\n",
    "\n",
    "        # weight initialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.features(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def _make_dense_block(self, nblock, inner_channels):\n",
    "        dense_block = nn.Sequential()\n",
    "        for i in range(nblock):\n",
    "            dense_block.add_module('bottle_neck_layer_{}'.format(i), BottleNeck(inner_channels, self.growth_rate))\n",
    "            inner_channels += self.growth_rate\n",
    "        return dense_block\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyDenseNet121([6,12,24,6]).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72cf698",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(3, 224, 224), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da2b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
